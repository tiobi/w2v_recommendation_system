{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Word2Vec Model Generator (beta) by for teamD\n",
    "### 간단 사용법:\n",
    "### 0. 압축 해제한 디렉터리를 그대로 사용하셔야 합니다.\n",
    "### 1.  brand_names 에 알고자 하는 브랜드 이름을 리스트 형식으로 입력합니다. (line 10)\n",
    "### 2. 학습하고자 하는 텍스트의 수를 정합니다. (line 43, out of range 주의, len(text)권장)\n",
    "### 3.  Word2Vec 학습에서의 옵션을 설정합니다. \n",
    "####    'min_count' :   등장 횟수가 n 이하인 단어는 무시\n",
    "####    'size' :   n차원짜리 벡터스페이스에 embedding\n",
    "####    'sg' :   0이면 CBOW, 1이면 skip-gram을 사용한다 (skip-gram 권장)\n",
    "####    'batch_words':  사전을 구축할때 한번에 읽을 단어 수\n",
    "####    'iter' :  보통 딥러닝에서 말하는 epoch과 비슷한, 반복 횟수\n",
    "####    'workers' : multiprocessing.cpu_count()                (출처:blog.theeluwin.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries\n",
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import re\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "## input brand names below\n",
    "brand_names = [\"sns_치킨_total_cleaned\"]\n",
    "\n",
    "\n",
    "\n",
    "## load stopword library\n",
    "library = \"./source/lib/JlabMiner_library.csv\"\n",
    "f = open(library, 'r', encoding = \"utf-8\")\n",
    "data = csv.reader(f)\n",
    "next(data)\n",
    "stop_words = []\n",
    "for row in data:\n",
    "    stop_words.append(row[0])\n",
    "f.close()\n",
    "\n",
    "for i in range(len(stop_words)):\n",
    "    stop_words[i] = stop_words[i].strip()\n",
    "    \n",
    "    \n",
    "## begin processing\n",
    "for brand_name in brand_names:\n",
    "\n",
    "    #f = open(\"./source/data/instagram_\" + brand_name + \"_cleaned2.csv\", 'r', encoding = \"utf-8\")\n",
    "    f = open(\"./source/data/\" + brand_name + \".csv\", \"r\", encoding = \"utf-8\")\n",
    "    data = csv.reader(f)\n",
    "    f.close\n",
    "    next(data)\n",
    "\n",
    "    text = []\n",
    "    for row in data:\n",
    "        text.append(str(row[-1]))\n",
    "        \n",
    "       \n",
    "    ## removing stopwords form text\n",
    "    text_for_training = []\n",
    "    for i in range(len(text)):\n",
    "        buffer = []\n",
    "        for j in range(len(okt.pos(text[i], norm = True, stem = True))):\n",
    "            buffer.append(okt.pos(text[i], norm = True, stem = True)[j][0])\n",
    "        for word in buffer:\n",
    "            if word in stop_words:\n",
    "                buffer.remove(word)\n",
    "        text_for_training.append(' '.join(buffer))\n",
    "    \n",
    "    \n",
    "    ## regexp\n",
    "    for i in range(len(text_for_training)):\n",
    "        text_for_training[i] = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…0-9》]', '', text_for_training[i])\n",
    "        \n",
    "       \n",
    "    ## string to list in list\n",
    "    buff = []\n",
    "    for i in range(len(text_for_training)):\n",
    "        buff.append(text_for_training[i].split(\" \"))            \n",
    "\n",
    "    ## save models   \n",
    "    wModel = Word2Vec(list(buff), size = 200, window = 3, min_count=3, sg=1, workers = 4) \n",
    "    #wModel.save(\"./source/model/word2vec_\" + brand_name + \".model\")\n",
    "    wModel.save(\"word2vec_치킨_total.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45865"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Instruction\n",
    "### 1. 저장한 모델을 불러옵니다. \n",
    "### 2. 아래 명령어를 사용하여 Word2Vec의 기능을 활용할 수 있습니다.\n",
    "#### 2-1. model.wv.vocab : 모델에 저장된 Vocab를 확인합니다. \n",
    "#### 2-2. model.wv.most_similar(\" KeyWord \", topn = n ) : KeyWord 와 유사도가 가장 높은 단어를 n 개만큼 보여줍니다.\n",
    "#### 2-3. model.wv.similarity(\" KW1 \", \" KW2 \") : KW1 과 KW2 의 유사도를 나타냅니다.\n",
    "#### 2-4. 이외의 명령어는 링크에서 확인할 수 있습니다 : https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "## 통합 모델을 보려면 total을 입력하세요!!\n",
    "brand = \"치킨_total\"\n",
    "model = Word2Vec.load(\"./source/model/word2vec_\" + brand + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469846"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"저렴하다\", \"비싸다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12699"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6212535\n",
      "0.7723217\n",
      "0.5868928\n",
      "0.7389085\n"
     ]
    }
   ],
   "source": [
    "for word in [\"신라면\", \"불닭볶음면\", \"짜파게티\", \"너구리\"]:\n",
    "\n",
    "    print(model.wv.similarity(word, \"맵다\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Vector Map (구현중)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors  = model.wv\n",
    "vocabs = word_vectors.vocab.keys()\n",
    "word_vector_list = [word_vectors[v] for v in vocabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "xys = pca.fit_transform(word_vector_list)\n",
    "xs = xys[:,0]\n",
    "ys = xys[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.scatter(xs, ys, marker = \"o\")\n",
    "for i, v in enumerate(vocabs):\n",
    "    if len(v) > 1:\n",
    "        plt.annotate(v, xy = (xs[i], ys[i]), fontname = \"nanumGothic\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
